{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries to use\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def thresh_image(img, thresh=(0, 255)):\n",
    "    filtered = img.copy()\n",
    "    filtered[filtered <= thresh[0]] = 0\n",
    "    filtered[filtered > thresh[1]] = 0\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_binary(img):\n",
    "    binary = np.zeros_like(img)\n",
    "    binary[img > 0] = 1\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Calculate the x and y gradients\n",
    "    grad_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    grad_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction,\n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(grad_y), np.absolute(grad_x))\n",
    "    filtered = absgraddir.copy()\n",
    "    filtered[absgraddir <= thresh[0]] = 0\n",
    "    filtered[absgraddir > thresh[1]] = 0\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mag_thresh(img, sobel_kernel=3, thresh=(0, 255)):\n",
    "    grad_x = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "    grad_y = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "    # Calculate the magnitude \n",
    "    abs_grad = np.sqrt(grad_x**2 + grad_y**2)\n",
    "    # Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    scaled_grad = np.uint8(255*abs_grad/np.max(abs_grad))\n",
    "    # Filter pixel that do not fit within thresholds\n",
    "    filtered = scaled_grad.copy()\n",
    "    filtered[scaled_grad <= thresh[0]] = 0\n",
    "    filtered[scaled_grad > thresh[1]] = 0\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def thresholding(img, thresholds):\n",
    "    # we asume image is read in BGR form\n",
    "    rgb_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # convert from BGR to HSL\n",
    "    hls_image = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    # Thresholding channel s from a hls image\n",
    "    filt_s = thresh_image(hls_image[:,:,2], thresh=thresholds['thresh_s'])\n",
    "    # Thresholding channel r from a rgb image\n",
    "    filt_r = thresh_image(rgb_image[:,:,0], thresh=thresholds['thresh_r'])\n",
    "    # Let's add values from both images filtered\n",
    "    add_im = filt_r.astype(int)\n",
    "    add_im += filt_s\n",
    "    # Normalize results to 255\n",
    "    add_im = add_im / add_im.max() * 255\n",
    "    # Calculate gradient thresholded images\n",
    "    gray = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)\n",
    "    grad_mag = mag_thresh(gray, sobel_kernel=12, thresh=thresholds['thresh_mag'])\n",
    "    grad_dir = dir_threshold(gray, sobel_kernel=15, thresh=thresholds['thresh_dir'])\n",
    "    # Combine all images\n",
    "    final_im = 1.8 * to_binary(thresh_image(add_im, thresh=thresholds['thresh_color'])) * 255\n",
    "    final_im += 1 * (grad_dir / grad_dir.max() * 255)\n",
    "    final_im += 2 * (grad_mag / grad_mag.max() * 255)\n",
    "    # Normalize results to 255\n",
    "    final_im = final_im / final_im.max() * 255\n",
    "    # Create a thresholded binary image of the combined image.\n",
    "    # we also applied a gaussian blur to smooth out noise\n",
    "    blur_gray = cv2.GaussianBlur(final_im,(3, 3), 0)\n",
    "    binary = to_binary(thresh_image(blur_gray, thresh=thresholds['thresh_final']))\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def line_mask(h=720, w=1280, point1=(0,0), point2=(720, 1280), band = 150):\n",
    "    mask = np.zeros((h, w), np.int8)\n",
    "    cv2.line(mask, point1, point2, (1,0,0), band)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_lane(img, bandwidth, line):\n",
    "    try:\n",
    "        # Let's see where the lane starts at the bottom of the picture\n",
    "        histogram = np.sum(img[int(img.shape[0]/3):,:], axis=0)\n",
    "        # finding the right and left peak of the histogram would give a good approximation of where the lane is\n",
    "        midpoint = np.int(histogram.shape[0]/2)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        # Create a mask for our region of interest\n",
    "        left_mask= line_mask(h=img.shape[0], w=img.shape[1],\n",
    "                             point1=(leftx_base, img.shape[0]),\n",
    "                             point2=(leftx_base, 0),\n",
    "                             band = bandwidth)\n",
    "        right_mask = line_mask(h=img.shape[0], w=img.shape[1],\n",
    "                               point1=(rightx_base, img.shape[0]), \n",
    "                               point2=(rightx_base, 0),\n",
    "                               band = bandwidth)\n",
    "        left_lane = cv2.bitwise_and(img, img, mask=left_mask)\n",
    "        right_lane = cv2.bitwise_and(img, img, mask=right_mask)\n",
    "        # fit a straight line through our points\n",
    "        # Carefull with what is x and y depending if we use image or matrix form\n",
    "        y_fit, x_fit = np.nonzero(left_lane) # y_fit is first component, rows in matrix\n",
    "        l_lane_line = np.polyfit(y_fit, x_fit, 1) # x and y are inverted from a \"normal\" polynomial\n",
    "        y_fit, x_fit = np.nonzero(right_lane) # y_fit is first component, rows in matrix\n",
    "        r_lane_line = np.polyfit(y_fit, x_fit, 1) # x and y are inverted from a \"normal\" polynomial\n",
    "        # Create reference point for new line\n",
    "        left_base = (int(l_lane_line[0] * 720 + l_lane_line[1]) , 720)\n",
    "        left_top = (int(l_lane_line[1]) , 0)\n",
    "        right_base = (int(r_lane_line[0] * 720 + r_lane_line[1]) , 720)\n",
    "        right_top = (int(r_lane_line[1]) , 0)\n",
    "        # Repeat the masking to improve the result but now with the line obtained before\n",
    "        # We'll also fit a degree two polynomial\n",
    "        # Update the mask for our region of interest\n",
    "        left_mask= line_mask(h=img.shape[0], w=img.shape[1], point1=left_base, point2=left_top)\n",
    "        right_mask = line_mask(h=img.shape[0], w=img.shape[1], point1=right_base, point2=right_top)\n",
    "        left_lane = cv2.bitwise_and(img, img, mask=left_mask)\n",
    "        right_lane = cv2.bitwise_and(img, img, mask=right_mask)\n",
    "        # fit a degree two polynomial through our points and points from previous n frames\n",
    "        # Carefull with what is x and y depending if we use image or matrix form\n",
    "        line.left_y_fit.appendleft(np.nonzero(left_lane)[0])\n",
    "        line.left_x_fit.appendleft(np.nonzero(left_lane)[1])\n",
    "        line.right_y_fit.appendleft(np.nonzero(right_lane)[0])\n",
    "        line.right_x_fit.appendleft(np.nonzero(right_lane)[1])\n",
    "        if len(line.right_x_fit) > line.n:\n",
    "            line.left_y_fit.pop()\n",
    "            line.left_x_fit.pop()\n",
    "            line.right_y_fit.pop()\n",
    "            line.right_x_fit.pop()\n",
    "        y_fit = np.concatenate(line.left_y_fit)\n",
    "        x_fit = np.concatenate(line.left_x_fit)\n",
    "        l_polynomial = np.polyfit(y_fit, x_fit, 2) # x and y are inverted from a \"normal\" polynomial\n",
    "        y_fit = np.concatenate(line.right_y_fit)\n",
    "        x_fit = np.concatenate(line.right_x_fit)\n",
    "        r_polynomial = np.polyfit(y_fit, x_fit, 2) # x and y are inverted from a \"normal\" polynomial\n",
    "        # return polynomial coefficients\n",
    "        return (l_polynomial, r_polynomial)\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_lane(img, lane):\n",
    "    y_value = img.shape[0]\n",
    "    ploty = np.linspace(0, y_value-1, num=y_value)\n",
    "    l_polynomial, r_polynomial = lane\n",
    "    left_fit = l_polynomial[0] * ploty ** 2 + l_polynomial[1] * ploty + l_polynomial[2]\n",
    "    right_fit = r_polynomial[0] * ploty ** 2 + r_polynomial[1] * ploty + r_polynomial[2]\n",
    "    # copy img to keep original\n",
    "    lane_warp = img.copy()\n",
    "    # zero the image\n",
    "    lane_warp[:] = 0\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fit, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fit, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    cv2.fillPoly(lane_warp, np.int_([pts]), (0,255, 0))\n",
    "    # unwarp the image to the original space\n",
    "    lane = cv2.warpPerspective(lane_warp, Minv, (img.shape[1], img.shape[0]))\n",
    "    result = cv2.addWeighted(img, 1, lane, 0.3, 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # number of frames to average\n",
    "        self.n = 8\n",
    "        # x values of left line to fit from n last frames\n",
    "        self.left_x_fit = deque()\n",
    "        # y values of left line to fit from n last frames\n",
    "        self.left_y_fit = deque()\n",
    "        # x values of right line to fit from n last frames\n",
    "        self.right_x_fit = deque()\n",
    "        # y values of right line to fit from n last frames\n",
    "        self.right_y_fit = deque()\n",
    "        #polynomial coefficients to use in current frame\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #alpha update strength\n",
    "        self.alpha = 0.8\n",
    "        #pixel scale\n",
    "        lane_pixel_width = 960 - 320\n",
    "        self.ym_per_pixel = 30 / 720\n",
    "        self.xm_per_pixel = 3.7 / lane_pixel_width\n",
    "    \n",
    "    def update_line(self, lane):\n",
    "        if self.current_fit[-1].any() and lane:\n",
    "            self.current_fit = self.current_fit * (1 - self.alpha) +  np.array(lane) * self.alpha\n",
    "            self.detected = True\n",
    "        elif lane:\n",
    "            self.current_fit = np.array(lane)\n",
    "            self.detected = True\n",
    "        else:\n",
    "            self.detected = False\n",
    "    \n",
    "    def calc_radius_pos(self):\n",
    "        # Calculate radius for both left and right\n",
    "        # Scale pixels to meter and fit polynomial again\n",
    "        y_value = 719 * self.ym_per_pixel # hardcoded for 720p video\n",
    "        y_fit = np.concatenate(line.left_y_fit) \n",
    "        x_fit = np.concatenate(line.left_x_fit)\n",
    "        l_polynomial_m = np.polyfit(y_fit * self.ym_per_pixel, x_fit * self.xm_per_pixel, 2)\n",
    "        y_fit = np.concatenate(line.right_y_fit)\n",
    "        x_fit = np.concatenate(line.right_x_fit)\n",
    "        r_polynomial_m = np.polyfit(y_fit * self.ym_per_pixel, x_fit * self.xm_per_pixel, 2)\n",
    "        # assigment for clarity\n",
    "        A, B, C = l_polynomial_m\n",
    "        R_left = (1 + (2 * A * y_value + B) ** 2) ** (3 / 2) / np.absolute(2 * A)\n",
    "        A, B, C = r_polynomial_m\n",
    "        R_right = (1 + (2 * A * y_value + B) ** 2) ** (3 / 2) / np.absolute(2 * A)\n",
    "        # maybe an average is a better estimate\n",
    "        self.radius_of_curvature = (R_right + R_left) / 2\n",
    "        # calculate position here too, reuse of fit\n",
    "        x_max = np.dot(r_polynomial_m, np.array([y_value**2, y_value, 1]))\n",
    "        x_min = np.dot(l_polynomial_m, np.array([y_value**2, y_value, 1]))\n",
    "        mid_lane = (x_max + x_min) / 2\n",
    "        mid_image = (1280 * self.xm_per_pixel) / 2 # image with hardcoded\n",
    "        self.line_base_pos = mid_image  - mid_lane\n",
    "        return self.radius_of_curvature, self.line_base_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_frame(img, mtx, dist_coef, thresholds, line):\n",
    "    un_dis = cv2.undistort(img, mtx, dist_coef, None, mtx)\n",
    "    thresholded = thresholding(un_dis, thresholds)\n",
    "    warped = cv2.warpPerspective(thresholded, M, (thresholded.shape[1], thresholded.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    lane = find_lane(warped, 250, line)\n",
    "    line.update_line(lane)\n",
    "    im = plot_lane(img, line.current_fit)\n",
    "    radius, pos = line.calc_radius_pos()\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(im,'Road Curvature {:.1f}m - Car Position {:.2f}m'.format(radius, pos), (200,50), font, 1,(255,255,255),2)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading calibration from files\n",
    "mtx = np.load('camera_matrix.npy')\n",
    "dist_coef = np.load('distortion_coeff.npy')\n",
    "# read perspective from files\n",
    "M = np.load('direct_persp_trans.npy')\n",
    "Minv = np.load('inverse_persp_trans.npy')\n",
    "\n",
    "thresh_values = {'thresh_s':(100, 255), 'thresh_r':(190,255), 'thresh_color':(110,255),\n",
    "                  'thresh_dir':(0.8,1.2), 'thresh_mag':(30,150), 'thresh_final':(110, 255)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, ImageSequenceClip\n",
    "from IPython.display import HTML\n",
    "def process_video(img):\n",
    "    # my code assumes image is read in BGR as it is by opencv. Image from moviepy come as RBG\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    image_bgr = process_frame(img, mtx, dist_coef, thresh_values, line)\n",
    "    return cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./project_video_processed.mp4\n",
      "[MoviePy] Writing video ./project_video_processed.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [09:12<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./project_video_processed.mp4 \n",
      "\n",
      "CPU times: user 1h 39min 38s, sys: 3min 19s, total: 1h 42min 58s\n",
      "Wall time: 9min 12s\n"
     ]
    }
   ],
   "source": [
    "line = Line()\n",
    "video_output = './project_video_processed.mp4'\n",
    "clip = VideoFileClip('./project_video.mp4')\n",
    "clip_processed = clip.fl_image(process_video) #NOTE: this function expects color images!!\n",
    "%time clip_processed.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./challenge_video_processed.mp4\n",
      "[MoviePy] Writing video ./challenge_video_processed.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 485/485 [03:07<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./challenge_video_processed.mp4 \n",
      "\n",
      "CPU times: user 33min 19s, sys: 1min 7s, total: 34min 26s\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "line = Line()\n",
    "video_output = './challenge_video_processed.mp4'\n",
    "clip = VideoFileClip('./challenge_video.mp4')\n",
    "clip_processed = clip.fl_image(process_video) #NOTE: this function expects color images!!\n",
    "%time clip_processed.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./harder_challenge_video_processed.mp4\n",
      "[MoviePy] Writing video ./harder_challenge_video_processed.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1199/1200 [09:04<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./harder_challenge_video_processed.mp4 \n",
      "\n",
      "CPU times: user 1h 33min 28s, sys: 3min 17s, total: 1h 36min 45s\n",
      "Wall time: 9min 5s\n"
     ]
    }
   ],
   "source": [
    "line = Line()\n",
    "video_output = './harder_challenge_video_processed.mp4'\n",
    "clip = VideoFileClip('./harder_challenge_video.mp4')\n",
    "clip_processed = clip.fl_image(process_video) #NOTE: this function expects color images!!\n",
    "%time clip_processed.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
